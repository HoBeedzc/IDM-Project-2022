{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Case Study II: Document Classification\n",
    "In this case, we have two categories of emails, in which one category is about hockey and the other is about baseball. The data is in the folder **classification**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module and define global variables\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "PUNCTUATION = \"~!@#$%^&*()_+`{}|\\[\\]\\:\\\";\\-\\\\\\='<>?,./\"\n",
    "STEMMER = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cell\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Firstly preprocess the documents into numerical data (Record data). The preprocessing guidelines can be found in the **introduction slides (SMO)**, consider using tf-idf (referring to Question 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stop_word(word):\n",
    "    return word in  stopwords.words('english')\n",
    "\n",
    "def stem_word(word):\n",
    "    return STEMMER.stem(word)\n",
    "\n",
    "def filter_line(line):\n",
    "    return re.sub(r'[{}]+'.format(PUNCTUATION), ' ', line.strip('\\n')).strip().lower()\n",
    "\n",
    "def walk_load_files(path):\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "             with open(os.path.join(dirname, filename),errors='ignore') as f:\n",
    "                yield filename,f\n",
    "\n",
    "def walk_filter_lines(path):\n",
    "    for _,f in walk_load_files(path):\n",
    "        for line in f.readlines():\n",
    "            yield filter_line(line)\n",
    "\n",
    "def build_vocabulary_base(base_dir='/kaggle/input/emailtexts/data/emailtexts'):\n",
    "    vocabulary_base = {}\n",
    "    for line in walk_filter_lines(base_dir):\n",
    "        for i in line.split():\n",
    "            if is_stop_word(i):\n",
    "                continue\n",
    "            word = stem_word(i)\n",
    "            vocabulary_base[word] = vocabulary_base.get(word,0) + 1\n",
    "    return vocabulary_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the tf-idf value\n",
    "\"\"\"\n",
    "Follow the steps below:\n",
    "- Calculate the tf value of each word\n",
    "- Calculate the idf value of each word\n",
    "- Compute the tf-idf value\n",
    "\"\"\"\n",
    "def cal_file_tf(vocabulary_base,filehandler):\n",
    "    res = {}\n",
    "    all_words = 0\n",
    "    # init res dict\n",
    "    for word,_ in vocabulary_base.items():\n",
    "        res[word] = 0\n",
    "    for line in filehandler:\n",
    "        for word in filter_line(line).split():\n",
    "            all_words += 1\n",
    "            if is_stop_word(word):\n",
    "                continue\n",
    "            word = stem_word(word)\n",
    "            res[word] += 1\n",
    "    # compute tf\n",
    "    for word,count in res.items():\n",
    "        res[word] = count/all_words\n",
    "    return res\n",
    "\n",
    "def tf(vocabulary_base,base_dir):\n",
    "    tf_dic = {}\n",
    "    for filename,f in walk_load_files(base_dir):\n",
    "        tf_dic[filename] = cal_file_tf(vocabulary_base,f)\n",
    "    # tf_df = pd.DataFrame(tf_dic)\n",
    "    return tf_dic\n",
    "\n",
    "def idf(vocabulary_base,tf_dic):\n",
    "    idf_dic = {}\n",
    "    for word,_ in vocabulary_base.items():\n",
    "        count = 0\n",
    "        file_num = 0\n",
    "        for _,tf_v in tf_dic.items():\n",
    "            file_num += 1\n",
    "            if tf_v[word] == 0:\n",
    "                continue\n",
    "            count += 1\n",
    "        if not count:print(word)\n",
    "        idf_dic[word] = math.log((1+file_num)/count)\n",
    "    return idf_dic\n",
    "\n",
    "def tf_idf(vocabulary_base,base_dir='/kaggle/input/emailtexts/data/emailtexts'):\n",
    "    tf_dic = tf(vocabulary_base,base_dir)\n",
    "    idf_dic = idf(vocabulary_base,tf_dic)\n",
    "    tf_idf_dic = {}\n",
    "    for filename,tf_vec in tf_dic.items():\n",
    "        value = {}\n",
    "        for word,_ in vocabulary_base.items():\n",
    "            value[word] = tf_vec[word]*idf_dic[word]\n",
    "        tf_idf_dic[filename] = value\n",
    "    tfidf_df = pd.DataFrame(tf_idf_dic).T\n",
    "    return tfidf_df,tf_idf_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: ./data/classification/baseball/.DS_Store: No such file or directory\n",
      "rm: ./data/classification/hockey/.DS_Store: No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spl2</th>\n",
       "      <th>po</th>\n",
       "      <th>cwru</th>\n",
       "      <th>edu</th>\n",
       "      <th>sam</th>\n",
       "      <th>lubchanski</th>\n",
       "      <th>subject</th>\n",
       "      <th>joe</th>\n",
       "      <th>robbi</th>\n",
       "      <th>stadium</th>\n",
       "      <th>...</th>\n",
       "      <th>helsingfor</th>\n",
       "      <th>ifk</th>\n",
       "      <th>1897</th>\n",
       "      <th>exager</th>\n",
       "      <th>proopos</th>\n",
       "      <th>heintz</th>\n",
       "      <th>gradual</th>\n",
       "      <th>scandinavia</th>\n",
       "      <th>deduct</th>\n",
       "      <th>variant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102700</th>\n",
       "      <td>0.072688</td>\n",
       "      <td>0.038134</td>\n",
       "      <td>0.051662</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>0.040465</td>\n",
       "      <td>0.072688</td>\n",
       "      <td>4.809941e-06</td>\n",
       "      <td>0.041958</td>\n",
       "      <td>0.059740</td>\n",
       "      <td>0.067337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104403</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.731733e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104631</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.172990e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105989</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.939409e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104890</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.116975e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54735</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.616107e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54507</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.312373e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53722</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.961884e-07</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.014997</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54163</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.631617e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53948</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.161251e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1989 rows × 18103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            spl2        po      cwru       edu       sam  lubchanski  \\\n",
       "102700  0.072688  0.038134  0.051662  0.007540  0.040465    0.072688   \n",
       "104403  0.000000  0.000000  0.000000  0.001713  0.000000    0.000000   \n",
       "104631  0.000000  0.000000  0.000000  0.001538  0.000000    0.000000   \n",
       "105989  0.000000  0.000000  0.000000  0.001843  0.000000    0.000000   \n",
       "104890  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "...          ...       ...       ...       ...       ...         ...   \n",
       "54735   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "54507   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "53722   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "54163   0.000000  0.000000  0.000000  0.004951  0.000000    0.000000   \n",
       "53948   0.000000  0.050125  0.000000  0.005947  0.000000    0.000000   \n",
       "\n",
       "             subject       joe     robbi   stadium  ...  helsingfor       ifk  \\\n",
       "102700  4.809941e-06  0.041958  0.059740  0.067337  ...    0.000000  0.000000   \n",
       "104403  2.731733e-06  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
       "104631  8.172990e-07  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
       "105989  2.939409e-06  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
       "104890  1.116975e-05  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
       "...              ...       ...       ...       ...  ...         ...       ...   \n",
       "54735   3.616107e-06  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
       "54507   1.312373e-06  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
       "53722   4.961884e-07  0.005771  0.000000  0.000000  ...    0.007498  0.007498   \n",
       "54163   2.631617e-06  0.000000  0.000000  0.000000  ...    0.000000  0.000000   \n",
       "53948   3.161251e-06  0.000000  0.052351  0.000000  ...    0.000000  0.000000   \n",
       "\n",
       "            1897    exager   proopos    heintz   gradual  scandinavia  \\\n",
       "102700  0.000000  0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "104403  0.000000  0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "104631  0.000000  0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "105989  0.000000  0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "104890  0.000000  0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "...          ...       ...       ...       ...       ...          ...   \n",
       "54735   0.000000  0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "54507   0.000000  0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "53722   0.007498  0.007498  0.007498  0.007498  0.014997     0.007498   \n",
       "54163   0.000000  0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "53948   0.000000  0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "\n",
       "          deduct   variant  \n",
       "102700  0.000000  0.000000  \n",
       "104403  0.000000  0.000000  \n",
       "104631  0.000000  0.000000  \n",
       "105989  0.000000  0.000000  \n",
       "104890  0.000000  0.000000  \n",
       "...          ...       ...  \n",
       "54735   0.000000  0.000000  \n",
       "54507   0.000000  0.000000  \n",
       "53722   0.007498  0.007498  \n",
       "54163   0.000000  0.000000  \n",
       "53948   0.000000  0.000000  \n",
       "\n",
       "[1989 rows x 18103 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use tf-idf to preprocess the documents into numerical data.\n",
    "BASE_DIR4 = './data/classification'\n",
    "# remove mac os index file .DS_Store\n",
    "os.system(\"rm ./data/classification/.DS_Store\")\n",
    "os.system(\"rm ./data/classification/baseball/.DS_Store\")\n",
    "os.system(\"rm ./data/classification/hockey/.DS_Store\")\n",
    "tc_vb = build_vocabulary_base(base_dir=BASE_DIR4)\n",
    "tc_tfidf_df,tc_tf_idf_dic = tf_idf(vocabulary_base=tc_vb,base_dir=BASE_DIR4)\n",
    "tc_tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Use SVMs to classify the documents and test the classification results with 5-fold cross validation. You should report the precision, recall, and F1-measure of each fold and the average values. (Recommend LIBSVM to implement SVMs. You can refer to the tutorial slides in evaluating the results.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spl2</th>\n",
       "      <th>po</th>\n",
       "      <th>cwru</th>\n",
       "      <th>edu</th>\n",
       "      <th>sam</th>\n",
       "      <th>lubchanski</th>\n",
       "      <th>subject</th>\n",
       "      <th>joe</th>\n",
       "      <th>robbi</th>\n",
       "      <th>stadium</th>\n",
       "      <th>...</th>\n",
       "      <th>ifk</th>\n",
       "      <th>1897</th>\n",
       "      <th>exager</th>\n",
       "      <th>proopos</th>\n",
       "      <th>heintz</th>\n",
       "      <th>gradual</th>\n",
       "      <th>scandinavia</th>\n",
       "      <th>deduct</th>\n",
       "      <th>variant</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102700</th>\n",
       "      <td>0.072688</td>\n",
       "      <td>0.038134</td>\n",
       "      <td>0.051662</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>0.040465</td>\n",
       "      <td>0.072688</td>\n",
       "      <td>4.809941e-06</td>\n",
       "      <td>0.041958</td>\n",
       "      <td>0.059740</td>\n",
       "      <td>0.067337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104403</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.731733e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104631</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.172990e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105989</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.939409e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104890</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.116975e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54735</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.616107e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54507</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.312373e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53722</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.961884e-07</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.014997</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54163</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.631617e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53948</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.161251e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1989 rows × 18104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            spl2        po      cwru       edu       sam  lubchanski  \\\n",
       "102700  0.072688  0.038134  0.051662  0.007540  0.040465    0.072688   \n",
       "104403  0.000000  0.000000  0.000000  0.001713  0.000000    0.000000   \n",
       "104631  0.000000  0.000000  0.000000  0.001538  0.000000    0.000000   \n",
       "105989  0.000000  0.000000  0.000000  0.001843  0.000000    0.000000   \n",
       "104890  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "...          ...       ...       ...       ...       ...         ...   \n",
       "54735   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "54507   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "53722   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "54163   0.000000  0.000000  0.000000  0.004951  0.000000    0.000000   \n",
       "53948   0.000000  0.050125  0.000000  0.005947  0.000000    0.000000   \n",
       "\n",
       "             subject       joe     robbi   stadium  ...       ifk      1897  \\\n",
       "102700  4.809941e-06  0.041958  0.059740  0.067337  ...  0.000000  0.000000   \n",
       "104403  2.731733e-06  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "104631  8.172990e-07  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "105989  2.939409e-06  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "104890  1.116975e-05  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "54735   3.616107e-06  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "54507   1.312373e-06  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "53722   4.961884e-07  0.005771  0.000000  0.000000  ...  0.007498  0.007498   \n",
       "54163   2.631617e-06  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "53948   3.161251e-06  0.000000  0.052351  0.000000  ...  0.000000  0.000000   \n",
       "\n",
       "          exager   proopos    heintz   gradual  scandinavia    deduct  \\\n",
       "102700  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "104403  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "104631  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "105989  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "104890  0.000000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "...          ...       ...       ...       ...          ...       ...   \n",
       "54735   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "54507   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "53722   0.007498  0.007498  0.007498  0.014997     0.007498  0.007498   \n",
       "54163   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "53948   0.000000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "\n",
       "         variant  LABEL  \n",
       "102700  0.000000      0  \n",
       "104403  0.000000      0  \n",
       "104631  0.000000      0  \n",
       "105989  0.000000      0  \n",
       "104890  0.000000      0  \n",
       "...          ...    ...  \n",
       "54735   0.000000      1  \n",
       "54507   0.000000      1  \n",
       "53722   0.007498      1  \n",
       "54163   0.000000      1  \n",
       "53948   0.000000      1  \n",
       "\n",
       "[1989 rows x 18104 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add label to tf-idf dataframe,0 for baseball and 1 for hockey\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "\n",
    "\n",
    "def add_label(df,label_dir):\n",
    "    label = {}\n",
    "    for dirname, _, filenames in os.walk(label_dir):\n",
    "        for filename in filenames:\n",
    "            label[filename] = dirname.split('/')[-1]\n",
    "    for i in df.index:\n",
    "        if label[i] == 'baseball':\n",
    "            df.loc[i, 'LABEL'] = 0\n",
    "        else:\n",
    "            df.loc[i, 'LABEL'] = 1\n",
    "    df[\"LABEL\"] = df[\"LABEL\"].astype(\"int\")\n",
    "    return df\n",
    "\n",
    "email_dataset = add_label(tc_tfidf_df,BASE_DIR4)\n",
    "email_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:49, 21.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# use Naive Bayes to classification the email.\n",
    "def train_svm_model(data):\n",
    "    models = []\n",
    "    tests = []\n",
    "    kf = KFold(n_splits=5,shuffle=True)\n",
    "    for train_index,test_index in tqdm(kf.split(data)):\n",
    "        gnb = SVC()\n",
    "        train = data.iloc[train_index]\n",
    "        test = data.iloc[test_index]\n",
    "        models.append(gnb.fit(train.iloc[:,:-1], train[\"LABEL\"]))\n",
    "        tests.append(test)\n",
    "    return models,tests\n",
    "\n",
    "models,tests = train_svm_model(email_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: precision 0.9842105263157894, recall 0.9689119170984456, F1-measure 0.9765013054830286.\n",
      "Fold 1: precision 1.0, recall 0.915, F1-measure 0.9556135770234987.\n",
      "Fold 2: precision 0.9856459330143541, recall 0.958139534883721, F1-measure 0.9716981132075472.\n",
      "Fold 3: precision 0.9777777777777777, recall 0.946236559139785, F1-measure 0.9617486338797814.\n",
      "Fold 4: precision 0.9842931937172775, recall 0.9353233830845771, F1-measure 0.9591836734693876.\n",
      "Avg: precision 0.9863854861650398, recall 0.9447222788413058, F1-measure 0.9649490606126486.\n"
     ]
    }
   ],
   "source": [
    "# report result for the classification\n",
    "# precision, recall, and F1-measure of each fold and the average values.\n",
    "\n",
    "def report_result(models,tests):\n",
    "    ps,rs,fs = [],[],[]\n",
    "    for i in range(len(models)):\n",
    "        y_true = tests[i][\"LABEL\"]\n",
    "        y_pred = models[i].predict(tests[i].iloc[:,:-1])\n",
    "        ps.append(precision_score(y_true,y_pred))\n",
    "        rs.append(recall_score(y_true,y_pred))\n",
    "        fs.append(f1_score(y_true,y_pred))\n",
    "        print(f\"Fold {i}: precision {ps[-1]}, recall {rs[-1]}, F1-measure {fs[-1]}.\")\n",
    "    print(f\"Avg: precision {np.mean(ps)}, recall {np.mean(rs)}, F1-measure {np.mean(fs)}.\")\n",
    "\n",
    "report_result(models,tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) **Bonus (5 extra points).** Implement Sequential Minimal Optimization (SMO) by following the introduction slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4w/x2czcsyx1m58qm0lp_wbk1jm0000gn/T/ipykernel_59108/1085361638.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  target[target == 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loops:100/100 Finish!\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "0.8902877697841727\n",
      "0.9782608695652174\n",
      "0.9322033898305085\n"
     ]
    }
   ],
   "source": [
    "# 本代码部分内容参考自 https://zhuanlan.zhihu.com/p/157858995\n",
    "# 本代码部分内容参考自 \n",
    "\n",
    "def decision_function_output(i):\n",
    "    global m,b\n",
    "    return np.sum([alpha[j] * target[j] * kernel(point[j], point[i]) for j in range(m)]) - b\n",
    "\n",
    "def svm_output(alphas, target, kernel, X_train, x_test, b):\n",
    "    result = (alphas * target) @ kernel(X_train, x_test) - b\n",
    "    return result\n",
    "\n",
    "def linear_kernel(x,y,b=1):\n",
    "    #线性核函数\n",
    "    result = x @ y.T + b\n",
    "    return result\n",
    "\n",
    "def gaussian_kernel(x,y, sigma=1):\n",
    "    #高斯核函数\n",
    "    if np.ndim(x) == 1 and np.ndim(y) == 1:\n",
    "        result = np.exp(-(np.linalg.norm(x-y,2))**2/(2*sigma**2))\n",
    "    elif(np.ndim(x)>1 and np.ndim(y) == 1) or (np.ndim(x) == 1 and np.ndim(y)>1):\n",
    "        result = np.exp(-(np.linalg.norm(x-y, 2, axis=1)**2)/(2*sigma**2))\n",
    "    elif np.ndim(x) > 1 and np.ndim(y) > 1 :\n",
    "        result = np.exp(-(np.linalg.norm(x[:, np.newaxis]- y[np.newaxis, :], 2, axis = 2) ** 2)/(2*sigma**2))\n",
    "    return result\n",
    "\n",
    "def get_error(i1):\n",
    "    if 0< alpha[i1] < C:\n",
    "        return errors[i1]\n",
    "    else:\n",
    "        return decision_function_output(i1) - target[i1]\n",
    "\n",
    "C = 20\n",
    "b = 0\n",
    "target = email_dataset.iloc[500:1500,:][\"LABEL\"]\n",
    "target[target == 0] = -1\n",
    "target = np.array(target)\n",
    "point = np.array(email_dataset.iloc[500:1500,400:1400])\n",
    "m,n = np.shape(point)\n",
    "tol = 0.01\n",
    "eps = 0.01\n",
    "alpha = [0 for _ in range(len(point))]\n",
    "kernel = linear_kernel\n",
    "errors = svm_output(alpha, target, kernel, point, point, b) - target\n",
    "\n",
    "\n",
    "def takeStep(i1,i2):\n",
    "    global b\n",
    "    if i1 == i2:\n",
    "        return 0\n",
    "    alph1 = alpha[i1]\n",
    "    y1 = target[i1]\n",
    "    E1 = get_error(i1)\n",
    "    alph2 = alpha[i2]\n",
    "    y2 = target[i2]\n",
    "    E2 = get_error(i2)\n",
    "    s = y1*y2\n",
    "    # Compute L, H\n",
    "    if(y1 != y2):   \n",
    "        L = max(0, alph2 - alph1)\n",
    "        H = min(C, C + alph2 - alph1)\n",
    "    elif (y1 == y2):\n",
    "        L = max(0, alph1+alph2 - C)\n",
    "        H = min(C, alph1 + alph2)\n",
    "    if L == H:\n",
    "        return 0\n",
    "    k11 = kernel(point[i1],point[i1])\n",
    "    k12 = kernel(point[i1],point[i2])\n",
    "    k22 = kernel(point[i2],point[i2])\n",
    "    eta = 2*k12-k11-k22\n",
    "    if eta < 0:\n",
    "        a2 = alph2 - y2*(E1-E2)/eta\n",
    "        if a2 < L:\n",
    "            a2 = L\n",
    "        elif a2 > H:\n",
    "            a2 = H\n",
    "    else:\n",
    "        f1 = y1*(E1 + b) - alph1*k11 - s*alph2*k12\n",
    "        f2 = y2 * (E2 + b) - s* alph1 * k12 - alph2 * k22\n",
    "        L1 = alph1 + s*(alph2 - L)\n",
    "        H1 = alph1 + s*(alph2 - H)\n",
    "        Lobj = L1 * f1 + L * f2 + 0.5 * (L1 ** 2) * k11 + 0.5 * (L**2) * k22 + s * L * L1 * k12\n",
    "        Hobj = H1 * f1 + H * f2 + 0.5 * (H1**2) * k11 + 0.5 * (H**2) * k22 + s * H * H1 * k12\n",
    "\n",
    "        if Lobj < Hobj - eps:\n",
    "            a2 = H\n",
    "        elif Lobj > Hobj + eps:\n",
    "            a2 = L\n",
    "        else:\n",
    "            a2 = alph2\n",
    "\n",
    "    if a2 <1e-8:\n",
    "        a2 = 0.0\n",
    "    elif a2 > (C - 1e-8):\n",
    "        a2 = C\n",
    "\n",
    "    if (np.abs(a2 - alph2) < eps * (a2 + alph2 + eps)):\n",
    "        return 0\n",
    "\n",
    "    a1 = alph1 + s * (alph2 - a2)\n",
    "\n",
    "    #更新 bias b的值 Equation (J20)\n",
    "    b1 = E1 + y1*(a1 - alph1) * k11 + y2 * (a2 - alph2) * k12 + b\n",
    "    #equation (J21)\n",
    "    b2 = E2 + y1*(a1 - alph1) * k12 + y2 * (a2 - alph2) * k22 + b\n",
    "    # Set new threshoold based on if a1 or a2 is bound by L and/or H\n",
    "    if 0 < a1 and a1 < C:\n",
    "        b_new =b1\n",
    "    elif 0 < a2 and a2 < C:\n",
    "        b_new = b2\n",
    "    #Average thresholds if both are bound\n",
    "    else:\n",
    "        b_new = (b1 + b2) * 0.5\n",
    "    #update model threshold\n",
    "    b = b_new\n",
    "\n",
    "    #优化完了，更新差值矩阵的对应值\n",
    "    #同时更新差值矩阵其它值\n",
    "    errors[i1] = 0\n",
    "    errors[i2] = 0\n",
    "    #更新差值 Equation (12)\n",
    "    for i in range(m):\n",
    "        if 0 < alpha[i] < C:\n",
    "            errors[i] += y1*(a1 - alph1)*kernel(point[i1],point[i]) + y2*(a2 - alph2)*kernel(point[i2], point[i]) + b - b_new\n",
    "    alpha[i1] = a1\n",
    "    alpha[i2] = a2\n",
    "    return 1\n",
    "\n",
    "\n",
    "\n",
    "def examineExample(i2):\n",
    "    y2 = target[i2]\n",
    "    alph2 = alpha[i2]\n",
    "    E2 = get_error(i2)\n",
    "    r2 = E2*y2\n",
    "    if (r2 < -tol and alph2 < C) or (r2 > tol and alph2 > 0):\n",
    "        if (len(alpha) - alpha.count(0) - alpha.count(C) > 1):\n",
    "            if errors[i2] > 0:\n",
    "                i1 = np.argmin(errors)\n",
    "            elif errors[i2] <= 0:\n",
    "                i1 = np.argmax(errors)\n",
    "            if takeStep(i1,i2):\n",
    "                return 1\n",
    "        rand = random.randint(0,len(alpha))\n",
    "        for i in range(len(alpha)):\n",
    "            if alpha[(i+rand)%len(alpha)] == 0 or alpha[(i+rand)%len(alpha)] == C:\n",
    "                continue\n",
    "            if takeStep((i+rand)%len(alpha),i2):\n",
    "                return 1\n",
    "        rand = random.randint(0,len(alpha))\n",
    "        for i in range(len(alpha)):\n",
    "            i1 = (i+rand)%len(alpha)\n",
    "            if takeStep(i1,i2):\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "def train():\n",
    "    numChanged = 0\n",
    "    examineAll = 1\n",
    "    loopnum = 0\n",
    "    totaloop = 100\n",
    "    while (numChanged > 0 or examineAll):\n",
    "        numChanged = 0\n",
    "        if loopnum == totaloop:\n",
    "           break\n",
    "        else:\n",
    "            loopnum += 1\n",
    "            print(f\"\\rLoops:{loopnum}/{totaloop}\",end=\"\")\n",
    "        if examineAll:\n",
    "            for i in range(len(point)):\n",
    "                numChanged != examineExample(i)\n",
    "        else:\n",
    "            for i in range(len(alpha)):\n",
    "                if alpha[i] != 0 or alpha[i] != C:\n",
    "                    numChanged += examineExample(i)\n",
    "        if examineAll == 1:\n",
    "            examineAll = 1\n",
    "        elif numChanged == 0:\n",
    "            examineAll = 1\n",
    "    print(\" Finish!\")\n",
    "    return -1\n",
    "\n",
    "train()\n",
    "\n",
    "output = svm_output(alpha, target, kernel, point, point, b)\n",
    "res = []\n",
    "for i in output:\n",
    "    if i > 0:\n",
    "        res.append(1)\n",
    "    else:\n",
    "        res.append(-1)\n",
    "print(target)\n",
    "print(res)\n",
    "\n",
    "print(precision_score(target,res))\n",
    "print(recall_score(target,res))\n",
    "print(f1_score(target,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
